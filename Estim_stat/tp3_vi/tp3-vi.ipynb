{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1296a3d",
   "metadata": {},
   "source": [
    "# TP3 - *Latent Dirichlet Allocation* et Inférence variationnelle \n",
    "\n",
    "## Estimation avancée - G3 SDIA\n",
    "\n",
    "Dans ce TP, on s'intéresse à la méthode \"inférence variationnelle\" (VI) qui permet d'approcher la loi a posteriori d'un modèle (généralement inconnue) par une autre loi plus simple (généralement un produit de lois bien connues). Nous allons l'appliquer à un modèle probabiliste pour des données textuelles, appelé *Latent Dirichlet Allocation* (LDA, qui n'a rien à voir avec la LDA *Linear Discriminant Analysis* du cours de ML).\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Renommer votre notebook sous la forme `tp3_Nom1_Nom2.ipynb`, et inclure le nom du binôme dans le notebook. \n",
    "\n",
    "2. Votre code, ainsi que toute sortie du code, doivent être commentés !\n",
    "\n",
    "3. Déposer votre notebook sur Moodle dans la section prévue à cet effet avant la date limite : 23 Décembre 2023, 23h59."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d382bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle as pkl\n",
    "import scipy as ss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22423210",
   "metadata": {},
   "source": [
    "### Partie 0 - Introduction\n",
    "\n",
    "LDA is a popular probabilistic model for text data, introducted in [Blei et al. (2003)](https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf). In this model, the posterior distribution is intractable, and we choose to resort to variational inference (note that a Gibbs sampler would be feasible as well, but would be very slow). In particular, the CAVI updates can be easily derived.\n",
    "\n",
    "In a few words, in LDA, each document is a mixture of topics, and each topic is a mixture of words. Uncovering those is the goal of *topic modeling*, and this is what we are going to do today. We will be using a collection of abstracts of papers published in JMLR (*Journal of Machine Learning Research*), one of the most prominent journals of the field.\n",
    "\n",
    "**Check the .pdf file describing the model.**\n",
    "The posterior is :\n",
    "$$p(\\boldsymbol{\\beta}, \\boldsymbol{\\theta}, \\mathbf{z} | \\mathcal{D}),$$\n",
    "which we are going to approximate in the following way :\n",
    "$$\\simeq \\left[ \\prod_{k=1}^K q(\\beta_k) \\right] \\left[ \\prod_{d=1}^D q(\\theta_d) \\right] \\left[ \\prod_{d=1}^D \\prod_{n=1}^{N_d} q(z_{dn}) \\right], $$\n",
    "with :\n",
    "* $q(\\beta_k)$ a Dirichlet distribution (of size V) with parameter $[\\lambda_{k1}, ...,\\lambda_{kV}]$\n",
    "* $q(\\gamma_d)$ a Dirichlet distribution (of size K) with parameter $[\\gamma_{d1}, ...,\\gamma_{dK}]$\n",
    "* $q(z_{dn})$ a Multinomial distribution (of size K) with parameter $[\\phi_{dn1}, ..., \\phi_{dnK}]$\n",
    "\n",
    "The updates are as follows :\n",
    "* $$\\lambda_{kv} = \\eta + \\sum_{d=1}^D \\sum_{n=1}^{N_d} w_{dnv} \\phi_{dnk} $$\n",
    "* $$\\gamma_{dk} = \\alpha + \\sum_{n=1}^{N_d} \\phi_{dnk}$$\n",
    "* $$ \\phi_{dnk} \\propto \\exp \\left( \\Psi(\\gamma_{dk}) + \\Psi(\\lambda_{k, w_{dn}}) - \\Psi(\\sum_{v=1}^V \\lambda_{kv}) \\right)$$\n",
    "\n",
    "$\\Psi$ is the digamma function, use `scipy.special.digamma`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c059097f",
   "metadata": {},
   "source": [
    "### Partie 1 - Les données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf0e5b",
   "metadata": {},
   "source": [
    "The data is already prepared, see code below. We have a total of 1898 abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41348f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "jmlr_papers = pkl.load(open(\"jmlr.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0694906",
   "metadata": {},
   "source": [
    "**Q1.** Fill in a list of keywords from the course, to see how many papers are about probabilistic ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "321a5acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 467 Bayesian papers out of 1898\n"
     ]
    }
   ],
   "source": [
    "bayesian_jmlr_papers = []\n",
    "\n",
    "for paper in jmlr_papers:\n",
    "    bayesian_keywords = [\"prior\", \"posterior\", \"likelihood\", \"MAP\",\"Bayes\"]\n",
    "    if any([kwd in paper[\"abstract\"] for kwd in bayesian_keywords]):\n",
    "        bayesian_jmlr_papers.append(paper)\n",
    "        \n",
    "print(\"There are\", str(len(bayesian_jmlr_papers))+\" Bayesian papers out of\", str(len(jmlr_papers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a047cf9",
   "metadata": {},
   "source": [
    "Let us now preprocess the data. It is important to remove so-called \"stop-words\" like a, is, but, the, of, have... Scikit-learn will do the job for us. We will keep only the top-1000 words from the abstracts.\n",
    "\n",
    "As a result, we get the count matrix $\\mathbf{C}$ of size $D = 1898 \\times V = 1000$. $c_{dv}$ is the number of occurrences of word $v$ in document $d$. This compact representation is called \"bag-of-words\". Of course from $\\mathbf{C}$ you easily recover the words, since in LDA the order does not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "855d2359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100' '16' '17' '18' '949' '_blank' 'ability' 'able' 'abs' 'according'\n",
      " 'account' 'accuracy' 'accurate' 'achieve' 'achieved' 'achieves' 'action'\n",
      " 'actions' 'active' 'adaboost' 'adaptive' 'addition' 'additional'\n",
      " 'additive' 'address' 'advantage' 'advantages' 'agent' 'aggregation' 'al'\n",
      " 'algorithm' 'algorithmic' 'algorithms' 'allow' 'allowing' 'allows'\n",
      " 'alternative' 'analysis' 'analyze' 'applicable' 'application'\n",
      " 'applications' 'applied' 'apply' 'applying' 'approach' 'approaches'\n",
      " 'appropriate' 'approximate' 'approximately' 'approximation'\n",
      " 'approximations' 'arbitrary' 'art' 'article' 'artificial' 'associated'\n",
      " 'assume' 'assumed' 'assumption' 'assumptions' 'asymptotic'\n",
      " 'asymptotically' 'attributes' 'available' 'average' 'averaging' 'bandit'\n",
      " 'base' 'based' 'basic' 'basis' 'batch' 'bayes' 'bayesian' 'behavior'\n",
      " 'belief' 'benchmark' 'best' 'better' 'bias' 'bib' 'binary' 'block'\n",
      " 'boosting' 'bound' 'bounded' 'bounds' 'br' 'build' 'building' 'called'\n",
      " 'capture' 'carlo' 'case' 'cases' 'causal' 'central' 'certain' 'chain'\n",
      " 'challenge' 'challenging' 'characterization' 'characterize' 'choice'\n",
      " 'chosen' 'class' 'classes' 'classical' 'classification' 'classifier'\n",
      " 'classifiers' 'close' 'closed' 'cluster' 'clustering' 'clusters' 'code'\n",
      " 'coding' 'coefficient' 'coefficients' 'collection' 'color' 'com'\n",
      " 'combination' 'combine' 'combined' 'combining' 'common' 'commonly'\n",
      " 'community' 'comparable' 'compare' 'compared' 'comparing' 'comparison'\n",
      " 'comparisons' 'competitive' 'complete' 'complex' 'complexity' 'component'\n",
      " 'components' 'compression' 'computation' 'computational'\n",
      " 'computationally' 'compute' 'computed' 'computer' 'computing' 'concept'\n",
      " 'concepts' 'condition' 'conditional' 'conditions' 'confidence' 'consider'\n",
      " 'considered' 'consistency' 'consistent' 'consists' 'constant'\n",
      " 'constrained' 'constraint' 'constraints' 'construct' 'constructing'\n",
      " 'construction' 'context' 'continuous' 'contrast' 'contribution' 'control'\n",
      " 'converge' 'convergence' 'convex' 'core' 'correct' 'correlation'\n",
      " 'corresponding' 'cost' 'costs' 'covariance' 'criteria' 'criterion'\n",
      " 'cross' 'current' 'curve' 'dag' 'data' 'datasets' 'deal' 'decision'\n",
      " 'decomposition' 'deep' 'define' 'defined' 'definite' 'degree'\n",
      " 'demonstrate' 'demonstrated' 'density' 'dependence' 'dependencies'\n",
      " 'dependent' 'depends' 'derive' 'derived' 'descent' 'described'\n",
      " 'describes' 'design' 'designed' 'detection' 'determine' 'deterministic'\n",
      " 'develop' 'developed' 'dictionary' 'difference' 'differences' 'different'\n",
      " 'difficult' 'dimension' 'dimensional' 'dimensionality' 'dimensions'\n",
      " 'direct' 'directed' 'direction' 'directly' 'dirichlet' 'discovery'\n",
      " 'discrete' 'discriminant' 'discriminative' 'discuss' 'discussed'\n",
      " 'distance' 'distances' 'distributed' 'distribution' 'distributions'\n",
      " 'divergence' 'document' 'does' 'domain' 'domains' 'dual' 'dynamic'\n",
      " 'dynamics' 'easily' 'easy' 'edges' 'effect' 'effective' 'effectiveness'\n",
      " 'effects' 'efficiency' 'efficient' 'efficiently' 'elements' 'ell_1' 'em'\n",
      " 'embedding' 'empirical' 'empirically' 'enables' 'end' 'ensemble'\n",
      " 'entries' 'entropy' 'environment' 'epsilon' 'equivalence' 'equivalent'\n",
      " 'error' 'errors' 'especially' 'establish' 'established' 'estimate'\n",
      " 'estimated' 'estimates' 'estimating' 'estimation' 'estimator'\n",
      " 'estimators' 'et' 'euclidean' 'evaluate' 'evaluated' 'evaluation'\n",
      " 'evidence' 'exact' 'example' 'examples' 'exist' 'existence' 'existing'\n",
      " 'exists' 'expectation' 'expected' 'experimental' 'experiments' 'expert'\n",
      " 'experts' 'explicit' 'explicitly' 'exploit' 'exploiting' 'exploration'\n",
      " 'explore' 'exponential' 'expression' 'extend' 'extended' 'extension'\n",
      " 'extensions' 'extensive' 'fact' 'factor' 'factorization' 'factors'\n",
      " 'families' 'family' 'fast' 'faster' 'feature' 'features' 'field' 'fields'\n",
      " 'filtering' 'finally' 'finding' 'finite' 'fisher' 'fit' 'fitting' 'fixed'\n",
      " 'flexible' 'focus' 'following' 'font' 'form' 'formulation' 'formulations'\n",
      " 'framework' 'free' 'fully' 'function' 'functional' 'functions'\n",
      " 'fundamental' 'furthermore' 'future' 'games' 'gap' 'gaussian' 'gene'\n",
      " 'general' 'generalization' 'generalize' 'generalized' 'generally'\n",
      " 'generated' 'generating' 'generative' 'generic' 'geometric' 'geometry'\n",
      " 'github' 'given' 'gives' 'global' 'goal' 'good' 'gp' 'gradient' 'graph'\n",
      " 'graphical' 'graphs' 'gray' 'greedy' 'group' 'groups' 'guarantee'\n",
      " 'guarantees' 'hand' 'handle' 'hard' 'help' 'hidden' 'hierarchical' 'high'\n",
      " 'higher' 'highly' 'hilbert' 'hold' 'href' 'http' 'human' 'hypotheses'\n",
      " 'hypothesis' 'ica' 'idea' 'identify' 'identifying' 'ii' 'illustrate'\n",
      " 'image' 'images' 'implement' 'implementation' 'implementations'\n",
      " 'implemented' 'importance' 'important' 'improve' 'improved' 'improvement'\n",
      " 'improvements' 'improves' 'improving' 'include' 'includes' 'including'\n",
      " 'increasing' 'independence' 'independent' 'index' 'indicate' 'individual'\n",
      " 'induced' 'inference' 'infinite' 'influence' 'information' 'input'\n",
      " 'inputs' 'instance' 'instances' 'instead' 'interactions' 'interesting'\n",
      " 'interpretation' 'inthe' 'intractable' 'introduce' 'introduced'\n",
      " 'introduces' 'invariant' 'inverse' 'investigate' 'involves' 'involving'\n",
      " 'issue' 'issues' 'items' 'iteration' 'iterations' 'iterative' 'joint'\n",
      " 'kernel' 'kernels' 'key' 'knowledge' 'known' 'label' 'labeled' 'labels'\n",
      " 'lambda' 'language' 'large' 'larger' 'lasso' 'latent' 'layer' 'lead'\n",
      " 'leading' 'leads' 'learn' 'learned' 'learner' 'learners' 'learning'\n",
      " 'learns' 'level' 'li' 'library' 'like' 'likelihood' 'limit' 'limited'\n",
      " 'line' 'linear' 'linearly' 'literature' 'local' 'locally' 'log'\n",
      " 'logarithmic' 'logistic' 'long' 'loss' 'losses' 'low' 'lower' 'machine'\n",
      " 'machines' 'magnitude' 'main' 'make' 'makes' 'making' 'manifold' 'manner'\n",
      " 'map' 'margin' 'marginal' 'markov' 'match' 'matching' 'mathbb' 'mathcal'\n",
      " 'matlab' 'matrices' 'matrix' 'max' 'maximization' 'maximum' 'mcmc' 'mean'\n",
      " 'means' 'measure' 'measurements' 'measures' 'memory' 'message' 'method'\n",
      " 'methodology' 'methods' 'metric' 'minimal' 'minimax' 'minimization'\n",
      " 'minimize' 'minimizing' 'minimum' 'mining' 'missing' 'mixed' 'mixture'\n",
      " 'mixtures' 'model' 'modeling' 'models' 'monte' 'motivated' 'multi'\n",
      " 'multiclass' 'multiple' 'multivariate' 'mutual' 'naive' 'natural'\n",
      " 'naturally' 'nature' 'nbsp' 'near' 'nearest' 'necessary' 'need' 'needed'\n",
      " 'negative' 'neighbor' 'network' 'networks' 'neural' 'new' 'node' 'nodes'\n",
      " 'noise' 'noisy' 'non' 'nonlinear' 'nonparametric' 'norm' 'normal' 'norms'\n",
      " 'notion' 'novel' 'np' 'number' 'numbers' 'numerical' 'object' 'objective'\n",
      " 'objects' 'observation' 'observations' 'observed' 'obtain' 'obtained'\n",
      " 'obtaining' 'offers' 'ofthe' 'ones' 'online' 'onthe' 'open' 'operator'\n",
      " 'optimal' 'optimality' 'optimization' 'oracle' 'order' 'original'\n",
      " 'outperform' 'outperforms' 'output' 'outputs' 'overall' 'pac' 'package'\n",
      " 'pair' 'pairs' 'pairwise' 'paper' 'papers' 'parallel' 'parameter'\n",
      " 'parameters' 'parametric' 'partial' 'particular' 'particularly'\n",
      " 'partition' 'path' 'pattern' 'patterns' 'pca' 'pdf' 'penalized' 'penalty'\n",
      " 'perform' 'performance' 'performed' 'performs' 'perspective' 'phase'\n",
      " 'point' 'points' 'policies' 'policy' 'polynomial' 'popular' 'population'\n",
      " 'positive' 'possible' 'posterior' 'potential' 'power' 'powerful'\n",
      " 'practical' 'practice' 'precision' 'predict' 'predicting' 'prediction'\n",
      " 'predictions' 'predictive' 'predictor' 'predictors' 'presence' 'present'\n",
      " 'presented' 'presents' 'previous' 'previously' 'principal' 'principle'\n",
      " 'prior' 'priors' 'privacy' 'probabilistic' 'probabilities' 'probability'\n",
      " 'problem' 'problems' 'procedure' 'procedures' 'process' 'processes'\n",
      " 'processing' 'produce' 'product' 'program' 'programming' 'projection'\n",
      " 'propagation' 'properties' 'property' 'propose' 'proposed' 'provably'\n",
      " 'prove' 'provide' 'provided' 'provides' 'providing' 'purpose' 'python'\n",
      " 'quadratic' 'quality' 'queries' 'question' 'random' 'randomized' 'range'\n",
      " 'rank' 'ranking' 'rate' 'rates' 'real' 'recent' 'recently' 'recognition'\n",
      " 'recovery' 'reduce' 'reduced' 'reduces' 'reduction' 'regression' 'regret'\n",
      " 'regularization' 'regularized' 'reinforcement' 'related' 'relations'\n",
      " 'relationship' 'relationships' 'relative' 'relatively' 'relaxation'\n",
      " 'relevant' 'relies' 'rely' 'represent' 'representation' 'representations'\n",
      " 'represented' 'reproducing' 'require' 'required' 'requires' 'research'\n",
      " 'respect' 'response' 'restricted' 'result' 'resulting' 'results' 'reward'\n",
      " 'right' 'risk' 'rkhs' 'robust' 'robustness' 'role' 'rule' 'rules' 'run'\n",
      " 'running' 'sample' 'sampled' 'samples' 'sampling' 'scalable' 'scale'\n",
      " 'scales' 'scenarios' 'scheme' 'schemes' 'score' 'scoring' 'search'\n",
      " 'second' 'select' 'selection' 'semi' 'sense' 'sensitive' 'separation'\n",
      " 'sequence' 'sequences' 'sequential' 'series' 'set' 'sets' 'setting'\n",
      " 'settings' 'sgd' 'short' 'showing' 'shown' 'shows' 'showthat' 'signal'\n",
      " 'signals' 'significant' 'significantly' 'similar' 'similarity' 'simple'\n",
      " 'simulated' 'simulation' 'simulations' 'simultaneously' 'single'\n",
      " 'situations' 'size' 'sizes' 'small' 'smaller' 'smooth' 'social' 'soft'\n",
      " 'software' 'solution' 'solutions' 'solve' 'solved' 'solving' 'source'\n",
      " 'sources' 'space' 'spaces' 'sparse' 'sparsity' 'special' 'specific'\n",
      " 'specifically' 'specified' 'spectral' 'speed' 'squared' 'squares'\n",
      " 'stability' 'stable' 'stage' 'standard' 'state' 'stationary'\n",
      " 'statistical' 'statistics' 'step' 'steps' 'stochastic' 'strategies'\n",
      " 'strategy' 'strong' 'strongly' 'structural' 'structure' 'structured'\n",
      " 'structures' 'studied' 'studies' 'study' 'sub' 'subset' 'subsets'\n",
      " 'subspace' 'success' 'successfully' 'sufficient' 'suggest' 'suitable'\n",
      " 'sum' 'sup' 'supervised' 'support' 'surrogate' 'svm' 'svms' 'symmetric'\n",
      " 'synthetic' 'systems' 'table' 'takes' 'target' 'task' 'tasks' 'tdalign'\n",
      " 'technique' 'techniques' 'temporal' 'tensor' 'term' 'terms' 'test'\n",
      " 'testing' 'tests' 'text' 'thatthe' 'theorem' 'theoretic' 'theoretical'\n",
      " 'theoretically' 'theory' 'thispaper' 'threshold' 'tight' 'time' 'times'\n",
      " 'tool' 'toolbox' 'tools' 'topic' 'total' 'tr' 'tractable' 'trade'\n",
      " 'traditional' 'trained' 'training' 'transfer' 'treatment' 'tree' 'trees'\n",
      " 'true' 'type' 'types' 'typically' 'uncertainty' 'underlying'\n",
      " 'understanding' 'unified' 'uniform' 'universal' 'unknown' 'unlabeled'\n",
      " 'unlike' 'unsupervised' 'update' 'updates' 'upper' 'use' 'used' 'useful'\n",
      " 'usefulness' 'user' 'users' 'uses' 'using' 'usually' 'utility' 'v19'\n",
      " 'validation' 'value' 'valued' 'values' 'variable' 'variables' 'variance'\n",
      " 'variant' 'variants' 'variational' 'variety' 'various' 'varying' 'vector'\n",
      " 'vectors' 'version' 'versions' 'view' 'viewed' 'volume19' 'walk' 'way'\n",
      " 'weak' 'web' 'weight' 'weighted' 'weights' 'weshow' 'wide' 'widely'\n",
      " 'width' 'word' 'words' 'work' 'works' 'world' 'worst' 'years' 'yields'\n",
      " 'zero']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features = 1000, stop_words='english')\n",
    "X = vectorizer.fit_transform([paper[\"abstract\"] for paper in jmlr_papers])\n",
    "print(vectorizer.get_feature_names_out()) # Top-1000 words\n",
    "C = X.toarray() # Count matrix\n",
    "\n",
    "# Removing documents with 0 words\n",
    "idx = np.where(np.sum(C, axis = 1)==0)\n",
    "C = np.delete(C, idx, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e3267",
   "metadata": {},
   "source": [
    "**Q2.** How many elements of $\\mathbf{C}$ are non-zero ? Is this surprising ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c9b9ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1895, 1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba38e64",
   "metadata": {},
   "source": [
    "Only 3 documents have been removed out of the 1898. It makes sense since these are theoretical papers which contain a lot of scientifique and specifique terms and we should have at least one of the 1000 most pertinent terms in each document. \n",
    "The vocabulary in this corpus of texts is very rich as such it's not suprising that there's more than 1000 words used in these documents which aren't stop words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72726d44",
   "metadata": {},
   "source": [
    "### Partie 2 - Inférence variationnelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ada0b7f",
   "metadata": {},
   "source": [
    "As you know from the lecture, VI aims at maximizing the ELBO. I have prepared for you the function to compute the ELBO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb1f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import digamma, loggamma\n",
    "\n",
    "def ELBO(L, G, phi, a, e, W):\n",
    "    # Computes the ELBO with the values of the parameters L (Lambda), G (Gamma), and Phi\n",
    "    # a, e are hyperparameters (alpha and eta)\n",
    "    # W are the words (obsereved)\n",
    "    \n",
    "    # L - K x V matrix (variational parameters Lambda)\n",
    "    # G - D x K matrix (variational parameters Gamma)\n",
    "    # phi - List of D elements, each element is a Nd x K matrix (variational parameters Phi)\n",
    "    # a - Scalar > 0 (hyperparameter alpha)\n",
    "    # e - Scalar > 0 (hyperparameter eta)\n",
    "    # W - List of D elements, each element is a Nd x V matrix (observed words)\n",
    "    \n",
    "    e_log_B = (digamma(L).T - digamma(np.sum(L, axis = 1))).T\n",
    "    e_log_T = (digamma(G).T - digamma(np.sum(G, axis = 1))).T\n",
    "    \n",
    "    t1 = (e-1)*np.sum(e_log_B)\n",
    "    t2 = (a-1)*np.sum(e_log_T)\n",
    "\n",
    "    phi_s = np.zeros((D,K))\n",
    "    for d in range(0,D):\n",
    "        phi_s[d,:] = np.sum(phi[d], axis = 0)\n",
    "    t3 = np.sum(e_log_T*phi_s)\n",
    "    \n",
    "    tmp = np.zeros((K,V))\n",
    "    for d in range(0,D):\n",
    "        tmp = tmp + np.dot(phi[d].T, W[d])\n",
    "    t4 = np.sum(e_log_B*tmp)\n",
    "    \n",
    "    t5 = np.sum(loggamma(np.sum(L, axis = 1))) - np.sum(loggamma(L)) + np.sum((L-1)*e_log_B)\n",
    "    t6 = np.sum(loggamma(np.sum(G, axis = 1))) - np.sum(loggamma(G)) + np.sum((G-1)*e_log_T)\n",
    "\n",
    "    t7 = 0\n",
    "    for d in range(0,D):\n",
    "        t7 = t7 + np.sum(phi[d]*np.log(phi[d] + np.spacing(1)))\n",
    "\n",
    "    return t1 + t2 + t3 + t4 - t5 - t6 - t7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc0302",
   "metadata": {},
   "source": [
    "**Q1.** Transform the matrix $\\mathbf{C}$ into the observed words $\\mathbf{w}$. $\\mathbf{w}$ should be a list of $D$ elements, each element of the list being a $N_d \\times V$ matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf794ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = []\n",
    "# On itére sur les documents \n",
    "for i in range(C.shape[0]):\n",
    "    # On initialise la matrice de taille Nd x V\n",
    "    doc = np.zeros(((C[i]).sum(),C.shape[1]))\n",
    "    # k compteur pour les lignes qui va aller de 1 à Nd\n",
    "    k = 0\n",
    "    for j in range(doc.shape[1]):\n",
    "        if C[i,j] != 0:\n",
    "            # Les C[i,j] lignes suivantes seront identiques avec un 1 en j et 0 sinon\n",
    "            for counts in range(C[i,j]):\n",
    "                doc[k+counts,j] = 1\n",
    "            k += C[i,j]\n",
    "    W.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c0aa3d",
   "metadata": {},
   "source": [
    "**Q2.** Implement the CAVI algorithm. The updates are given at the beginning of the notebook. Monitor the convergence with the values of the ELBO (but start with a fixed number of iterations, like 50)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35664524",
   "metadata": {},
   "source": [
    "* $$\\lambda_{kv} = \\eta + \\sum_{d=1}^D \\sum_{n=1}^{N_d} w_{dnv} \\phi_{dnk} $$\n",
    "* $$\\gamma_{dk} = \\alpha + \\sum_{n=1}^{N_d} \\phi_{dnk}$$\n",
    "* $$ \\phi_{dnk} \\propto \\exp \\left( \\Psi(\\gamma_{dk}) + \\Psi(\\lambda_{k, w_{dn}}) - \\Psi(\\sum_{v=1}^V \\lambda_{kv}) \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea905414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres pour les distributions Dirichlet\n",
    "D =  len(W)\n",
    "V = 1000\n",
    "K = 10 \n",
    "L = np.random.rand(K,V)\n",
    "G = np.ones((D,K))/K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c14607df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAVI(W, K, a, e, seed): # Other arguments may be added\n",
    "    # L - K x V matrix (variational parameters Lambda)\n",
    "    # G - D x K matrix (variational parameters Gamma)\n",
    "    # phi - List of D elements, each element is a Nd x K matrix (variational parameters Phi)\n",
    "    np.random.seed(seed)\n",
    "    V= 1000\n",
    "    D =len(W)\n",
    "    # Initiliase Lambda values\n",
    "    L = np.random.rand(K,V)\n",
    "    # Initialise Gamma values\n",
    "    G = np.ones((D,K))/K \n",
    "    # initialise phi\n",
    "    phi = []\n",
    "    for d in range(D):\n",
    "        Nd = len(W[d])\n",
    "        phi_d = np.zeros((Nd,K))\n",
    "        for n in range(Nd):\n",
    "            for k in range(K):\n",
    "                phi_d[n][k] = np.exp(ss.special.digamma(G[d][k])+ ss.special.digamma(L[k][np.where(W[d][n]==1)[0][0]]) - ss.special.digamma(np.sum(L[k])))\n",
    "        phi.append(phi_d)\n",
    "    elbo = ELBO(L, G, phi, a, e, W)\n",
    "    n_iter = 0\n",
    "    liste_elbo = [elbo]\n",
    "    while n_iter <20:\n",
    "        print(f'iteration: {n_iter}')\n",
    "        # Update the variables of q\n",
    "        L = np.full((K,V),e)\n",
    "        G = np.full((D,K),a)\n",
    "        for d in range(D):\n",
    "            L += phi[d][:][:].transpose()@W[d][:][:]\n",
    "            G[d] += phi[d].sum(axis=0)\n",
    "\n",
    "        for d in range(len(W)):\n",
    "            Nd = len(W[d])\n",
    "            for n in range(Nd):\n",
    "                for k in range(K):\n",
    "                    phi[d][n][k] = np.exp(ss.special.digamma(G[d][k])+ ss.special.digamma(L[k][np.where(W[d][n]==1)[0][0]]) - ss.special.digamma(np.sum(L[k])))\n",
    "\n",
    "        # compute\n",
    "        res = ELBO(L, G, phi, a, e, W)\n",
    "        liste_elbo.append(res)\n",
    "        n_iter += 1\n",
    "    \n",
    "    return L, G, phi, liste_elbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51ebf025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAVI_opti(W, K, a, e, seed, max_iter=20): # Other arguments may be added\n",
    "    # L - K x V matrix (variational parameters Lambda)\n",
    "    # G - D x K matrix (variational parameters Gamma)\n",
    "    # phi - List of D elements, each element is a Nd x K matrix (variational parameters Phi)\n",
    "    np.random.seed(seed)\n",
    "    V= 1000\n",
    "    D =len(W)\n",
    "    # Initiliase Lambda values\n",
    "    L = np.random.rand(K,V)\n",
    "    # Initialise Gamma values\n",
    "    G = np.ones((D,K))/K \n",
    "    # initialise phi\n",
    "    phi = []\n",
    "    for d in range(D):\n",
    "        Nd = len(W[d])\n",
    "        phi_d = np.zeros((Nd, K))\n",
    "        # Calcul des termes digamma pour G[d]\n",
    "        digamma_G = ss.special.digamma(G[d])\n",
    "\n",
    "        for n in range(Nd):\n",
    "            indices = np.where(W[d][n] != 0)[0]\n",
    "            phi_d[n] = np.exp(digamma_G + ss.special.digamma(L[:, indices[0]]) - ss.special.digamma(np.sum(L, axis=1)))\n",
    "            phi_d[n] =  phi_d[n]/np.sum(phi_d[n])\n",
    "        phi.append(phi_d)\n",
    "\n",
    "    elbo = ELBO(L, G, phi, a, e, W)\n",
    "    n_iter = 0\n",
    "    liste_elbo = np.zeros(max_iter)\n",
    "    liste_elbo[0] = elbo\n",
    "    \n",
    "    while n_iter <max_iter:\n",
    "        print(f'iteration: {n_iter}')\n",
    "        # Update the variables of q\n",
    "        L = np.full((K,V),e)\n",
    "        G = np.full((D,K),a)\n",
    "        for d in range(D):\n",
    "            L += phi[d][:][:].transpose()@W[d][:][:]\n",
    "            G[d] += np.sum(phi[d],axis=0)\n",
    "\n",
    "\n",
    "        for d in range(D):\n",
    "            Nd = len(W[d])\n",
    "            #phi_d = np.zeros((Nd, K))\n",
    "            \n",
    "            # Calcul des termes digamma pour G[d]\n",
    "            digamma_G = ss.special.digamma(G[d])\n",
    "\n",
    "            for n in range(Nd):\n",
    "                indices = np.where(W[d][n] != 0)[0]\n",
    "                phi[d][n] = np.exp(digamma_G + ss.special.digamma(L[:, indices[0]]) - ss.special.digamma(np.sum(L, axis=1)))\n",
    "                phi[d][n] =  phi[d][n]/np.sum(phi[d][n])\n",
    "\n",
    "        # compute\n",
    "        liste_elbo[n_iter] = ELBO(L, G, phi, a, e, W)\n",
    "        n_iter += 1\n",
    "    \n",
    "    return L, G, phi, liste_elbo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b88160d",
   "metadata": {},
   "source": [
    "**Q3.** Run the algorithm with $K = 10$, $\\alpha = 0.5$, $\\eta = 0.1$. From the results, compute the MMSE of $\\lambda_{kv}$ and $\\gamma_{dk}$.\n",
    "\n",
    "**Bonus** : Re-run the algorithm several times with different initializations, and keep the solution which returns the highest ELBO.\n",
    "\n",
    "NB : In my implementation, one iteration of the CAVI algorithm takes about 4 seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee2cec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "iteration: 1\n",
      "iteration: 2\n",
      "iteration: 3\n",
      "iteration: 4\n",
      "iteration: 5\n",
      "iteration: 6\n",
      "iteration: 7\n",
      "iteration: 8\n",
      "iteration: 9\n",
      "iteration: 10\n",
      "iteration: 11\n",
      "iteration: 12\n",
      "iteration: 13\n",
      "iteration: 14\n",
      "iteration: 15\n",
      "iteration: 16\n",
      "iteration: 17\n",
      "iteration: 18\n",
      "iteration: 19\n",
      "iteration: 20\n",
      "iteration: 21\n",
      "iteration: 22\n",
      "iteration: 23\n",
      "iteration: 24\n",
      "iteration: 25\n",
      "iteration: 26\n",
      "iteration: 27\n",
      "iteration: 28\n",
      "iteration: 29\n",
      "iteration: 30\n",
      "iteration: 31\n",
      "iteration: 32\n",
      "iteration: 33\n",
      "iteration: 34\n",
      "iteration: 35\n",
      "iteration: 36\n",
      "iteration: 37\n",
      "iteration: 38\n",
      "iteration: 39\n",
      "iteration: 40\n",
      "iteration: 41\n",
      "iteration: 42\n",
      "iteration: 43\n",
      "iteration: 44\n",
      "iteration: 45\n",
      "iteration: 46\n",
      "iteration: 47\n",
      "iteration: 48\n",
      "iteration: 49\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "a = 0.5\n",
    "e = 0.1\n",
    "\n",
    "L, G, phi, list_ELBO = CAVI_opti(W, K, a, e, 123,max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "883be51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(50), list_ELBO)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc6553",
   "metadata": {},
   "source": [
    "**Q4.** Based on the MMSE estimates :\n",
    "* What are the top-10 words per topic ? With your machine learning knowledge, can you make sense of some of the topics ?\n",
    "* Choose one document at random and display its topic proportions. Comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef772fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "### YOUR CODE HERE\n",
    "#######"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e446f419",
   "metadata": {},
   "source": [
    "----- Your answer here -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13019da",
   "metadata": {},
   "source": [
    "**Q5.** Open questions :\n",
    "* What are some limitations of the LDA model ? Can you imagine an improvement ?\n",
    "* In this notebook, we have treated the hyperparameters as fixed. How could they be learned ?\n",
    "* Can you imagine a method to choose the number of topics ?\n",
    "* What strategies should we use to make the algorithm more efficient ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600e6149",
   "metadata": {},
   "source": [
    "**BONUS.** Papier-crayon. À partir du modèle, pouvez-vous dériver les lois conditionnelles de l'échantillonneur de Gibbs ? Pour rappel, nous avons besoin de ces lois pour dériver ensuite les updates de l'algorithme CAVI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
